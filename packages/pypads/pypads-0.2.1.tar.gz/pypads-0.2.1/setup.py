# -*- coding: utf-8 -*-
from setuptools import setup

packages = \
['pypads',
 'pypads.app',
 'pypads.app.injections',
 'pypads.app.misc',
 'pypads.bindings',
 'pypads.bindings.resources',
 'pypads.bindings.resources.mapping',
 'pypads.importext',
 'pypads.importext.semver',
 'pypads.importext.wrapping',
 'pypads.injections',
 'pypads.injections.analysis',
 'pypads.injections.loggers',
 'pypads.injections.loggers.mlflow',
 'pypads.injections.setup',
 'pypads.parallel',
 'pypads.utils']

package_data = \
{'': ['*']}

install_requires = \
['boltons>=19.3.0,<20.0.0',
 'cloudpickle>=1.3.0,<2.0.0',
 'loguru>=0.4.1,<0.5.0',
 'mlflow>=1.6.0,<2.0.0']

setup_kwargs = {
    'name': 'pypads',
    'version': '0.2.1',
    'description': 'PyPaDS aims to to add tracking functionality to machine learning libraries.',
    'long_description': '\n# PyPads\nBuilding on the [MLFlow](https://github.com/mlflow/mlflow/) toolset this project aims to extend the functionality for MLFlow, increase the automation and therefore reduce the workload for the user. The production of structured results is an additional goal of the extension.\n\n[![Documentation Status](https://readthedocs.org/projects/pypads/badge/?version=latest)](https://pypads.readthedocs.io/en/latest/?badge=latest)\n[![PyPI version](https://badge.fury.io/py/pypads.svg)](https://badge.fury.io/py/pypads)\n\n\n# Intalling\nThis tool requires those libraries to work:\n\n    Python (>= 3.6),\n    cloudpickle (>= 1.3.3),\n    mlflow (>= 1.6.0),\n    boltons (>= 19.3.0),\n    loguru (>=0.4.1)\n    \nPyPads only support python 3.6 and higher. To install pypads run this in you terminal\n\n**Using source code**\n\nFirst, you have to install **poetry** \n\n    pip install poetry\n    poetry build (in the root folder of the repository pypads/)\n\nThis would create two files under pypads/dist that can be used to install,\n\n    pip install dist/pypads-X.X.X.tar.gz\n    OR\n    pip install dist/pypads-X.X.X-py3-none-any.whl\n    \n \n**Using pip ([PyPi release](https://pypi.org/project/pypads/))**\n\nThe package can be found on PyPi in following [project](https://pypi.org/project/pypads/).\n\n    pip install pypads\n\n### Tests\nThe unit tests can be found under \'test/\' and can be executed using\n\n    poetry run pytest test/\n\n# Documentation\n\nFor more information, look into the [official documentation of PyPads](https://pypads.readthedocs.io/en/latest/).\n\n# Getting Started\n         \n### Usage example\npypads is easy to use. Just define what is needed to be tracked in the config and call PyPads.\n\nA simple example looks like the following,\n```python\nfrom pypads.app.base import PyPads\n# define the configuration, in this case we want to track the parameters, \n# outputs and the inputs of each called function included in the hooks (pypads_fit, pypads_predict)\nconfig = {"events": {\n    "parameters": {"on": ["pypads_fit"]},\n    "output": {"on": ["pypads_fit", "pypads_predict"]},\n    "input": {"on": ["pypads_fit"]}\n}}\n# A simple initialization of the class will activate the tracking\nPyPads(config=config)\n\n# An example\nfrom sklearn import datasets, metrics\nfrom sklearn.tree import DecisionTreeClassifier\n\n# load the iris datasets\ndataset = datasets.load_iris()\n\n# fit a model to the data\nmodel = DecisionTreeClassifier()\nmodel.fit(dataset.data, dataset.target) # pypads will track the parameters, output, and input of the model fit function.\n# get the predictions\npredicted = model.predict(dataset.data) # pypads will track only the output of the model predict function.\n```\n        \n        \nThe used hooks for each event are defined in the mapping json file where each hook represents the functions to listen to.\nIn the [sklearn mapping](pypads/bindings/resources/mapping/sklearn_0_19_1.json) json file, an example entry would be:\n\n    {\n      "name": "base sklearn estimator",\n      "other_names": [],\n      "implementation": {\n        "sklearn": "sklearn.base.BaseEstimator"\n      },\n      "hooks": {\n        "pypads_fit": [\n          "fit",\n          "fit_predict",\n          "fit_transform"\n        ],\n        "pypads_predict": [\n          "fit_predict",\n          "predict"\n        ],\n        "pypads_transform": [\n          "fit_transform",\n          "transform"\n        ]\n      }\n    }\n\nFor instance, "pypads_fit" is an event listener on any fit, fit_predict and fit_transform call made by the tracked model class which is in this case **BaseEstimator** that most estimators inherits from.\n\n### Defining hooks\nHooks are what triggers an "event" which is associated to one or more logger function in the mapping.\n\n#### Always\n    {\n      "name": "sklearn classification metrics",\n      "other_names": [],\n      "implementation": {\n        "sklearn": "sklearn.metrics.classification"\n      },\n      "hooks": {\n        "pypads_metric": "always"\n      }\n    }\nThis hook triggers always. If you annotate a module with this hook, all its functions and classes will be tracked.\n\n#### QualNameHook\n    {\n      "name": "sklearn classification metrics",\n      "other_names": [],\n      "implementation": {\n        "sklearn": "sklearn.metrics.classification"\n      },\n      "hooks": {\n        "pypads_metric": ["f1_score"]\n      }\n    }\nTracks function with a name matching the given expression by compiling a regex expression.\n\n#### PackageNameHook\n    {\n      "name": "sklearn classification metrics",\n      "other_names": [],\n      "implementation": {\n        "sklearn": "sklearn.metrics"\n      },\n      "hooks": {\n        "pypads_metric": [{"type": "package_name", "name":".*classification.*"}]\n      }\n    }\nTracks all attribute on module where package name is matching Regex.\n\n### Default Events, Hooks and Logging Functions\n\nThe default configuration of events/hooks and logging functions for PyPads:\n\n    DEFAULT_CONFIG = {"events": {\n    "init": {"on": ["pypads_init"]},\n    "parameters": {"on": ["pypads_fit"]},\n    "hardware": {"on": ["pypads_fit"]},\n    "output": {"on": ["pypads_fit", "pypads_predict"]},\n    "input": {"on": ["pypads_fit"], "with": {"_pypads_write_format": WriteFormats.text.name}},\n    "metric": {"on": ["pypads_metric"]},\n    "pipeline": {"on": ["pypads_fit", "pypads_predict", "pypads_transform", "pypads_metric"]},\n    "log": {"on": ["pypads_log"]}\n    },\n        "recursion_identity": False,\n        "recursion_depth": -1,\n        "log_on_failure": True}\n    \n    DEFAULT_LOGGING_FNS = {\n    "parameters": Parameters(),\n    "output": Output(_pypads_write_format=WriteFormats.text.name),\n    "input": Input(_pypads_write_format=WriteFormats.text.name),\n    "hardware": {Cpu(), Ram(), Disk()},\n    "metric": Metric(),\n    "autolog": MlflowAutologger(),\n    "pipeline": PipelineTracker(_pypads_pipeline_type="normal", _pypads_pipeline_args=False),\n    "log": Log(),\n    "init": LogInit()\n\nLoggers in pypads goes into three categories. Pre, Post run loggers and event based loggers.\n\n* Event based loggers:\n\n| Logger  | Event | Hook | Description\n| :-------------: |:----------:|: -----------:| ----------------|\n| LogInit  | init | \'pypads_init\'| Debugging purposes |\n| Log  | log | \'pypads_log\'| Debugging purposes |\n| Parameters  |  parameters | \'pypads_fit\'| tracks parameters of the tracked function call |\n| Cpu,Ram,Disk  |  hardware | \'pypads_fit\'| track usage information, properties and other info on CPU, Memory and Disk. |\n| Input  |  input | \'pypads_fit\' |tracks the input parameters of the current tracked function call. | \n| Output  | output | \'pypads_predict\', \'pypads_fit\' |Logs the output of the current tracked function call.| \n| Metric  | metric | \'pypads_metric\' |tracks the output of the tracked metric function. | \n| PipelineTracker  | pipeline | \'pypads_fit\',\'pypads_predict\', \'pypads_transform\', \'pypads_metrics\'|tracks the workflow of execution of the different pipeline elements of the experiment.| \n\n* Pre/Post run loggers:\n\n| Logger  | Pre/Post | Description\n| :-------------:|: -----------:| ----------------|\n| IGit  | Pre | Source code management and tracking|\n| ISystem  | Pre | System information (os,version,machine...)|\n| ICpu  |  Pre | Cpu information (Nbr of cores, max/min frequency)|\n| IRam  |  Pre | Memory information (Total RAM, SWAP)|\n| IDisk  |  Pre | Disk information (disk total space)| \n| IPid  | Pre | Process information (ID, command, cpu usage, memory usage)| \n| ISocketInfo  | Pre | Network information (hostname, ip address)| \n| IMacAddress  | Pre | Mac address |\n\n# Concept\nLogging results of machine learning workflows often shares similar structures and goals. You might want to track parameteres, loss functions, metrics or other characteristic numbers. While the produced output shares a lot of concepts and could be standardized, implementations are diverse and integrating them or their autologging functionality into such a standard needs manual labour. Each and every version of a library might change internal structures and hard coding interfaces can need intesive work. Pypads aims to feature following main techniques to handle autologging and standardization efforts:\n- **Automatic metric tracking:** TODO\n- **Automatic execution tracking:** TODO \n- **Community driven mapping files:** A means to log data from python libaries like sklearn. Interfaces are not added directly to MLFlows, but derived from versioned mapping files of frameworks.\n- **Output standardization:** TODO\n\n\n### PyPads class\nAs we have seen, a simple initialization of the class at the top of your code activate the tracking for libraries that has a mapping file defining the algorithms to track.\n\nBeside the configuration, **PyPads** takes other optional arguments.\n```python        \nclass PyPads(uri=None, name=None, mapping_paths=None, mapping=None, init_run_fns=None,\n                 include_default_mappings=True,\n                 logging_fns=None, config=None, reload_modules=False, reload_warnings=True, clear_imports=False,\n                 affected_modules=None)\n```\n[Source](https://github.com/padre-lab-eu/pypads/blob/0cb9f9bd5dff7753f7c47dc691d41edd0426a90a/pypads/base.py#L141)\n\n**Parameters**:\n> **uri : string, optional (default=None)** <br> Address of local or remote tracking server that **MLflow** uses to record runs. If None, then it tries to get the environment variable **\'MLFLOW_PATH\'** or the **\'HOMEPATH\'** of the user. \n> \n> **name : string, optional (default=None)** <br> Name of the **MLflow** experiment to track.\n>\n> **mapping_paths : list, optional (default=None)** <br> Absolute paths to additional mapping files.\n>\n> **mapping : dict, optional (default=None)** <br> Mapping to the logging functions to use for the tracking of the events. If None, then a DEFAULT_MAPPING is used which allow to log parameters, outputs or inputs.\n>\n> **init_run_fns : list, optional (default=None)** <br> Logging function to execute on tracking initialization.\n>\n> **include_default_mappings : boolean, optional (default=True)** <br> A flag whether to use the default provided mappings or not.\n>\n> **logging_fns : dict, optional (default=None)** <br> User defined logging functions to use where each dict item has to be \' "event": fn\' or \' "event": {fn1,fn2,...}\'.\n>\n> **config : dict, optional (default=None)** <br> A dictionary that maps the events defined in PyPads mapping files with the logging functions.\n>\n> **reload_modules : boolean, optional (default=False)** <br> Reload and duck punch already loaded modules before the tracking activation if set to True.\n>\n> **clear_imports: boolean, optional (default=False)** <br> Delete alredy loaded modules for sys.modules() if set to True.\n# Scientific work disclaimer\nThis was created in scope of scientific work of the Data Science Chair at the University of Passau. If you want to use this tool or any of its resources in your scientific work include a citation.\n\n# Acknowledgement\nThis work has been partially funded by the **Bavarian Ministry of Economic Affairs, Regional Development and Energy** by means of the funding programm **"Internetkompetenzzentrum Ostbayern"** as well as by the **German Federal Ministry of Education and Research** in the project **"Provenance Analytics"** with grant agreement number *03PSIPT5C*.\n',
    'author': 'Thomas WeiÃŸgerber',
    'author_email': 'thomas.weissgerber@uni-passau.de',
    'maintainer': None,
    'maintainer_email': None,
    'url': 'https://www.padre-lab.eu/',
    'packages': packages,
    'package_data': package_data,
    'install_requires': install_requires,
    'python_requires': '>=3.6.0,<4.0.0',
}


setup(**setup_kwargs)
