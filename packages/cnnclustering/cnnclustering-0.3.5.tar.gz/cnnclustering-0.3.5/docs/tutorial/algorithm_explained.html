
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Density based clustering explained &#8212; cnnclustering  documentation</title>
    <link rel="stylesheet" href="../_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="API Reference" href="../_source/api_reference.html" />
    <link rel="prev" title="Data input formats" href="data_input_formats.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container,
div.nbinput.container div.prompt,
div.nbinput.container div.input_area,
div.nbinput.container div[class*=highlight],
div.nbinput.container div[class*=highlight] pre,
div.nboutput.container,
div.nboutput.container div.prompt,
div.nboutput.container div.output_area,
div.nboutput.container div[class*=highlight],
div.nboutput.container div[class*=highlight] pre {
    background: none;
    border: none;
    padding: 0 0;
    margin: 0;
    box-shadow: none;
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    background: #f5f5f5;
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt a.copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
</style>
<div class="section" id="Density-based-clustering-explained">
<h1>Density based clustering explained<a class="headerlink" href="#Density-based-clustering-explained" title="Permalink to this headline">¶</a></h1>
<p>Learn in this tutorial about the basics of density-based clustering and how common-nearest-neighbours clustering works compared to other methods.</p>
<div class="section" id="Pre-requirements">
<h2>Pre-requirements<a class="headerlink" href="#Pre-requirements" title="Permalink to this headline">¶</a></h2>
<div class="section" id="Import-dependencies">
<h3>Import dependencies<a class="headerlink" href="#Import-dependencies" title="Permalink to this headline">¶</a></h3>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[303]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>from collections import deque
import sys

import matplotlib as mpl
import matplotlib.pyplot as plt
import networkx
import numpy as np
from scipy.integrate import quad
from scipy import stats
from scipy.spatial import cKDTree
from sklearn import datasets
from sklearn.preprocessing import StandardScaler
</pre></div>
</div>
</div>
<p>This notebook was created using Python 3.8.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span># Version information
print(sys.version)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
3.8.3 (default, May 15 2020, 15:24:35)
[GCC 8.3.0]
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span># Matplotlib configuration
mpl.rc_file(
    &quot;matplotlibrc&quot;,
    use_default_template=False
)
</pre></div>
</div>
</div>
</div>
<div class="section" id="Helper-functions">
<h3>Helper functions<a class="headerlink" href="#Helper-functions" title="Permalink to this headline">¶</a></h3>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[55]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>def gauss(x, sigma, mu):
    &quot;&quot;&quot;Gaussian PDF&quot;&quot;&quot;
    return (1 / (sigma * np.sqrt(2 * np.pi))
            * np.exp(-1 / 2 * ((x - mu) / sigma)**2))

def multigauss(x, sigma, mu):
    &quot;&quot;&quot;Multimodal gaussian PDF as linear combination of gaussian PDFs&quot;&quot;&quot;
    assert len(sigma) == len(mu)

    out = np.zeros_like(x)
    for s, m in zip(sigma, mu):
        out += gauss(x, s, m)
    return out / len(sigma)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>def determine_cuts(x, a, cutoff):
    &quot;&quot;&quot;Find points in space where density cutoff is crossed

    Args:
       x: coordinate
       a: density
       cutoff: density cutoff

    Returns:
       cuts: Array of coordinates where cutoff is crossed
    &quot;&quot;&quot;

    cuts = []
    dense = False  # Assume low density on left border
    for index, value in enumerate(a[1:], 1):
        if dense:
            if value &lt; cutoff:
                dense = False
                cuts.append((x[index] + x[index - 1]) / 2)
        else:
            if value &gt;= cutoff:
                dense = True
                cuts.append((x[index] + x[index - 1]) / 2)

    return np.asarray(cuts)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[94]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>class multigauss_distribution(stats.rv_continuous):
    &quot;&quot;&quot;Draw samples from a multimodal gaussian distribution&quot;&quot;&quot;

    def __init__(self, sigma, mu, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self._sigma = sigma
        self._mu = mu

    def _pdf(self, x):
        return multigauss(x, sigma=self._sigma, mu=self._mu)
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="Density-criteria">
<h2>Density criteria<a class="headerlink" href="#Density-criteria" title="Permalink to this headline">¶</a></h2>
<p>Density-based clustering defines clusters as <em>dense</em> regions in space, separated by <em>sparse</em> regions. But what is dense and what is sparse? This is commonly defined by a threshold, that is a density criterion that determines the clustering. In the case where we have a density function defined on a continuous coordinate, the density criterion manifests itself as a density iso-surface. Regions in which the density is higher than a cutoff set as density criterion qualify as <em>dense</em>, and therefore
represent a cluster. On the other hand, regions in which the density falls below the density criterion are considered <em>sparse</em> and do not constitute a part of a cluster. We can illustrate this on the example of a bimodal gaussian distribution in one dimension.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>xlimit = (-8, 8)
x = np.linspace(*xlimit, 101)

fig, ax = plt.subplots()
ax.plot(x, multigauss(x, sigma=[1, 1.5], mu=[-2, 2]))
ax.set(**{
    &quot;xlim&quot;: xlimit,
    &quot;xlabel&quot;: &quot;$x$&quot;,
    &quot;ylabel&quot;: &quot;probability density&quot;
})
plt.show()
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorial_algorithm_explained_14_0.png" src="../_images/tutorial_algorithm_explained_14_0.png" />
</div>
</div>
<p>We have two maxima in the distribution. An intuitive classification in clusters would separate the two peaks into two different clusters. In density based clustering we define the two clusters as the regions of high density where we have low density in between. By applying an iso-value cutoff on the density, we can specify what should be considered high or low density. In a dense region, the density is at least as high as the density criterion requires.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[43]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>density_criterion = 0.1

xlimit = (-8, 8)
x = np.linspace(*xlimit, 1001)
pdf = multigauss(x, sigma=[1, 1.5], mu=[-2, 2])
cuts = determine_cuts(x, pdf, density_criterion)
density_criterion_ = np.full_like(x, density_criterion)
dense = np.maximum(pdf, density_criterion_)

fig, ax = plt.subplots()
ax.plot(x, pdf)
ax.plot(x, density_criterion_, linestyle=&quot;--&quot;, color=&quot;k&quot;)
ax.fill_between(x, density_criterion_, dense)
for cut in cuts:
    ax.axvline(cut, color=&quot;gray&quot;, alpha=0.5)

ax.annotate(
    &quot;density criterion&quot;, (xlimit[0] * 0.975, density_criterion * 1.03),
    fontsize=&quot;small&quot;
)

ax.annotate(&quot;0&quot;, (cuts[0] * 1.2, 0))
ax.annotate(&quot;1&quot;, (cuts[1] * 2, 0))
ax.annotate(&quot;0&quot;, (cuts[2] * 0.2, 0))
ax.annotate(&quot;2&quot;, (cuts[3] * 0.8, 0))
ax.annotate(&quot;0&quot;, (cuts[3] * 1.2, 0))

ax.annotate(
    &quot;dense&quot;,
    xy=(2.2, multigauss(2.2, sigma=[1, 1.5], mu=[-2, 2])),
    xytext=(cuts[3] * 1.2, density_criterion * 1.5),
    arrowprops={&quot;arrowstyle&quot;: &quot;-&gt;&quot;}
)

ax.annotate(
    &quot;sparse&quot;,
    xy=(4, multigauss(4., sigma=[1, 1.5], mu=[-2, 2])),
    xytext=(cuts[3] * 1.2, density_criterion * 1.2),
    arrowprops={&quot;arrowstyle&quot;: &quot;-&gt;&quot;}
)

ax.set(**{
    &quot;xlim&quot;: xlimit,
    &quot;xlabel&quot;: &quot;$x$&quot;,
    &quot;ylabel&quot;: &quot;probability density&quot;
})
plt.show()
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorial_algorithm_explained_16_0.png" src="../_images/tutorial_algorithm_explained_16_0.png" />
</div>
</div>
<p>Choosing the density criterion in this way, defines the two clusters exactly as we would have expected. We can label the regions, i.e. we can assign a number to them, that denotes their cluster membership. We use 0 to indicate that a region is not part of any cluster and positive integers as cluster numbers. When we vary the density criterion, we can influence the outcome of the clustering by changing the definition of what is dense enough to be a cluster. This could leave us with both density
maxima in one cluster, clusters of different broadness, or not cluster at all.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[53]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>fig, Ax = plt.subplots(2, 2)
ax = Ax.flatten()

for i, d in enumerate([0.05, 0.09, 0.15, 0.22]):
    density_criterion = d

    xlimit = (-8, 8)
    x = np.linspace(*xlimit, 1001)
    pdf = multigauss(x, sigma=[1, 1.5], mu=[-2, 2])
    cuts = determine_cuts(x, pdf, density_criterion)
    density_criterion_ = np.full_like(x, density_criterion)
    dense = np.maximum(pdf, density_criterion_)


    ax[i].plot(x, pdf)
    ax[i].plot(x, density_criterion_, linestyle=&quot;--&quot;, color=&quot;k&quot;)
    ax[i].fill_between(x, density_criterion_, dense)
    for cut in cuts:
        ax[i].axvline(cut, color=&quot;gray&quot;, alpha=0.5)


    ax[i].set(**{
        &quot;xlim&quot;: xlimit,
    })

fig.tight_layout()
plt.show()
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorial_algorithm_explained_18_0.png" src="../_images/tutorial_algorithm_explained_18_0.png" />
</div>
</div>
<p>When we operate on data sets (in maybe high dimensional spaces), however, we normally do not have a continuous description of the density, that we can directly use. Instead we may have sample points from an underlying (unknown) distribution. To apply a density based clustering on them, we need to approximate the density in some way. For this approximation, quite a number of different possibilities exist, which provide a different notion of what density is or how it could be estimated from
scattered data. To illustrate this, let’s draw samples from the above used bimodal distribution to emulate data points.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[172]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>distribution = multigauss_distribution(
    sigma=[1, 1.5], mu=[-2, 2], a=-8, b=8, seed=11
)
samples = distribution.rvs(size=20)

xlimit = (-8, 8)
x = np.linspace(*xlimit, 1001)
pdf = multigauss(x, sigma=[1, 1.5], mu=[-2, 2])

fig, ax = plt.subplots()
ax.plot(x, pdf, color=&quot;gray&quot;, linestyle=&quot;--&quot;, alpha=0.5)

ax.set(**{
    &quot;xlim&quot;: xlimit,
    &quot;xlabel&quot;: &quot;$x$&quot;,
    &quot;ylabel&quot;: &quot;probability density&quot;
})

ax.plot(samples, np.zeros_like(samples), linestyle=&quot;&quot;,
        marker=&quot;|&quot;, markeredgewidth=0.75, markersize=15)

plt.show()
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorial_algorithm_explained_20_0.png" src="../_images/tutorial_algorithm_explained_20_0.png" />
</div>
</div>
<p>In the following we look into how density is deduced from points in terms of the following methods:</p>
<ul class="simple">
<li><p>DBSCAN</p></li>
<li><p>Jarvis-Patrick</p></li>
<li><p>CNN</p></li>
</ul>
<p>In general, point density can be expressed in simple terms by the number of points <span class="math notranslate nohighlight">\(n\)</span> found on an area <span class="math notranslate nohighlight">\(x\)</span> <span class="math notranslate nohighlight">\(\left(\rho = \frac{n}{x}\right)\)</span>.</p>
<div class="section" id="DBSCAN">
<h3>DBSCAN<a class="headerlink" href="#DBSCAN" title="Permalink to this headline">¶</a></h3>
<p>In DBSCAN local point density (so the density around a sample point) is accordingly expressed as the number of neighbouring points <span class="math notranslate nohighlight">\(k_r\)</span> with respect to a neighbour search radius <span class="math notranslate nohighlight">\(r\)</span>. The density criterion is formulated as such: Points that have at least <span class="math notranslate nohighlight">\(k\)</span> nearest neighbours in their neighbourhood <span class="math notranslate nohighlight">\(r\)</span> qualify as part of a dense region, i.e. a cluster. Points that fulfill the density criterion can be also referred to as <em>core points</em>. Additionally it is possible to
describe points that do not fulfill the density criterion themselves but are neighbours of those core points as <em>edge points</em>. For our samples above this could look as the followed if we choose the density criterion as <span class="math notranslate nohighlight">\(k=1\)</span> and <span class="math notranslate nohighlight">\(r=0.5\)</span>. To determine the number of neighbours for each point, we calculated pairwise point distances and compare them to <span class="math notranslate nohighlight">\(r\)</span>.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[179]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span># Density criterion
r = 0.5  # Neighbour search radius
k = 1    # Minimum number of neighbours

n_neighbours = np.array([
    # Neighbour within r?
    len(np.where((0 &lt; x) &amp; (x &lt;= r))[0])
    # distance matrix
    for x in np.absolute(np.subtract.outer(samples, samples))
])

dense = n_neighbours &gt;= k  # Point is part of dense region?
dense
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[179]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
array([ True,  True,  True,  True,  True,  True,  True,  True, False,
        True,  True,  True,  True,  True,  True, False,  True,  True,
       False,  True])
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[180]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>xlimit = (-8, 8)
x = np.linspace(*xlimit, 1001)
pdf = multigauss(x, sigma=[1, 1.5], mu=[-2, 2])

fig, ax = plt.subplots()
ax.plot(x, pdf, color=&quot;gray&quot;, linestyle=&quot;--&quot;, alpha=0.5)

ax.set(**{
    &quot;xlim&quot;: xlimit,
    &quot;xlabel&quot;: &quot;$x$&quot;,
    &quot;ylabel&quot;: &quot;probability density&quot;
})

for i, s in enumerate(samples):
    if dense[i]:
        c = &quot;#396ab1&quot;
    else:
        c = &quot;gray&quot;
    ax.plot(s, 0, linestyle=&quot;&quot;,
            marker=&quot;|&quot;, markeredgewidth=0.75, markersize=15,
            color=c)

labels = [
    (-4, &quot;1&quot;),
    (-2.8, &quot;2&quot;),
    (-1.8, &quot;0&quot;),
    (-0.8, &quot;3&quot;),
    (1, &quot;0&quot;),
    (1.8, &quot;4&quot;),
    (2.8, &quot;5&quot;),
    (3.8, &quot;0&quot;),
]

for position, l in labels:
    ax.annotate(l, (position, 0.02))

plt.show()
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorial_algorithm_explained_25_0.png" src="../_images/tutorial_algorithm_explained_25_0.png" />
</div>
</div>
<p>In this case we end up with 5 clusters, that are dense enough regions separated by low density areas. Like a change in the density iso-value as the density criterion for the continuous density function, a change of the cluster parameters <span class="math notranslate nohighlight">\(k\)</span> and <span class="math notranslate nohighlight">\(r\)</span> will determine the cluster result. Note, that we assigned the labels to the clusters by visual inspection. We will show later how to identify these isolated regions (connected components of core points) automatically.</p>
</div>
<div class="section" id="Jarvis-Patrick">
<h3>Jarvis-Patrick<a class="headerlink" href="#Jarvis-Patrick" title="Permalink to this headline">¶</a></h3>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>### CNN
</pre></div>
</div>
</div>
</div>
<div class="section" id="Summary-on-density-criteria">
<h3>Summary on density criteria<a class="headerlink" href="#Summary-on-density-criteria" title="Permalink to this headline">¶</a></h3>
<p>A point is part of a dense region if the point …</p>
<ul class="simple">
<li><p>DBSCAN: … has at least <span class="math notranslate nohighlight">\(k_r\)</span> neighbours within a radius <span class="math notranslate nohighlight">\(r\)</span></p></li>
<li><p>Jarvis-Patrick: … shares at least <span class="math notranslate nohighlight">\(c\)</span> common neighbours with a another point among their <span class="math notranslate nohighlight">\(k\)</span> nearest neighbours</p></li>
<li><p>CNN: … shares at least <span class="math notranslate nohighlight">\(c\)</span> common neighbours with a another point with respect to a radius <span class="math notranslate nohighlight">\(r\)</span></p></li>
</ul>
</div>
</div>
<div class="section" id="Identify-connected-components-of-points">
<h2>Identify connected components of points<a class="headerlink" href="#Identify-connected-components-of-points" title="Permalink to this headline">¶</a></h2>
<p>Classifying points as part of a dense or a sparse region according to a density criterion, is only one aspect of assigning points to clusters. We still need to identify groups of points that are part of the same region. In this context, we use the term <em>density reachable</em> to describe the situation where point is directly connected to a dense point. We also use the term <em>density connected</em> for points that are part of the same dense region, i.e. they are directly or indirectly connected to any
other point in the region by a chain of density reachable points. In other words, it is not enough to know which points are dense but we also need to be aware of the relationship between dense points. When we express this relationship in a graph, the problem of identifying clusters of density connected points comes down to finding connected components of nodes within this graph. For the methods we considered above, points are density reachable if they are neighbours of a dense point (with
respect to a radius <em>r</em> or one of the <span class="math notranslate nohighlight">\(k\)</span> nearest neighbours). In the above example, we where only interested in the information if a point was part of a dense region by checking the density criterion. Let’s now construct a density graph instead in which each dense point constitutes a node and each vertex represent the density reachability between two points. We neglect the concept of edge points (points that are not dense but density reachable from a dense point) for the sake of
simplicity here.</p>
<div class="section" id="id1">
<h3>DBSCAN<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[240]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span># Density criterion
r = 0.5  # Neighbour search radius
k = 1    # Minimum number of neighbours

neighbourhoods = [
    # Neighbour within r?
    np.where((0 &lt; x) &amp; (x &lt;= r))[0]
    # distance matrix
    for x in np.absolute(np.subtract.outer(samples, samples))
]

n_neighbours = np.asarray([len(x) for x in neighbourhoods])
dense = n_neighbours &gt;= k

# Construct graph as dictionary
# keys: dense points, values: density reachable points
graph = {}
for i, point in enumerate(neighbourhoods):
    if dense[i]:
        graph[i] = neighbourhoods[i][dense[neighbourhoods[i]]]

G = networkx.Graph(graph)
pos = networkx.spring_layout(G, iterations=10, seed=7)
networkx.draw(G, pos=pos, with_labels=True)
plt.show()
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorial_algorithm_explained_35_0.png" src="../_images/tutorial_algorithm_explained_35_0.png" />
</div>
</div>
<p>Once such a graph is constructed, graph traversal algorithms can be used to find the connected components of nodes within the graph. A generic way to do so using a breadth-first-search algorithm could look like this:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[250]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>labels = {}                          # Cluster label assignments
visited = {k: False for k in graph}  # Node has been assigned
queue = deque()                      # First-in-first-out queue
current = 1                          # Current cluster number

for point, connected in graph.items():
    # Source node
    if visited[point]:
        continue

    labels[point] = current
    visited[point] = True

    while True:
        for reachable in connected:
            if visited[reachable]:
                continue

            labels[reachable] = current
            visited[reachable] = True
            queue.append(reachable)

        if not queue:
            break

        point = queue.popleft()
        connected = graph[point]

    current += 1
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[251]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>labels
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[251]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{0: 1,
 11: 1,
 14: 1,
 17: 1,
 19: 1,
 1: 2,
 6: 2,
 16: 2,
 2: 3,
 4: 3,
 5: 3,
 7: 3,
 3: 4,
 10: 4,
 9: 5,
 12: 5,
 13: 5}
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[259]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>networkx.draw(G, pos=pos, with_labels=True, node_color=[x[1] for x in sorted(labels.items())])
plt.show()
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorial_algorithm_explained_39_0.png" src="../_images/tutorial_algorithm_explained_39_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[267]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>xlimit = (-8, 8)
x = np.linspace(*xlimit, 1001)
pdf = multigauss(x, sigma=[1, 1.5], mu=[-2, 2])

fig, ax = plt.subplots()
ax.plot(x, pdf, color=&quot;gray&quot;, linestyle=&quot;--&quot;, alpha=0.5)

ax.set(**{
    &quot;xlim&quot;: xlimit,
    &quot;xlabel&quot;: &quot;$x$&quot;,
    &quot;ylabel&quot;: &quot;probability density&quot;
})

colors = [&#39;#396ab1&#39;, &#39;#da7c30&#39;, &#39;#3e9651&#39;, &#39;#cc2529&#39;, &#39;#6b4c9a&#39;]
for i, s in enumerate(samples):
    if dense[i]:
        c = colors[labels[i] - 1]
    else:
        c = &quot;gray&quot;
    ax.plot(s, 0, linestyle=&quot;&quot;,
            marker=&quot;|&quot;, markeredgewidth=0.75, markersize=15,
            color=c)

labels_ = [
    (-4, &quot;2&quot;),
    (-2.8, &quot;1&quot;),
    (-1.8, &quot;0&quot;),
    (-0.8, &quot;3&quot;),
    (1, &quot;0&quot;),
    (1.8, &quot;4&quot;),
    (2.8, &quot;5&quot;),
    (3.8, &quot;0&quot;),
]

for position, l in labels_:
    ax.annotate(l, (position, 0.02))

plt.show()
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorial_algorithm_explained_40_0.png" src="../_images/tutorial_algorithm_explained_40_0.png" />
</div>
</div>
</div>
</div>
<div class="section" id="CNN-clustering-in-detail">
<h2>CNN clustering in detail<a class="headerlink" href="#CNN-clustering-in-detail" title="Permalink to this headline">¶</a></h2>
<div class="alert alert-block alert-info"><p><strong>Note:</strong> This section is currently under developement.</p>
</div><p>In practice, one does not necessarily need to construct a density connectivity graph in its entirety beforehand. It is also possible to start from another input structure and explore the connectivity while traversing the structure. We will now show a variant of the CNN clustering procedure, starting from pre-computed neighbourhoods in more detail. For this, we generate a small example data set of 200 points in 2D.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[272]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>noisy_circles, _ = datasets.make_circles(
    n_samples=200,
    factor=.5,
    noise=.05,
    random_state=8
    )

noisy_circles = StandardScaler().fit_transform(noisy_circles)

fig, ax = plt.subplots()
ax.plot(*noisy_circles.T, &quot;k.&quot;)
ax.set(**{
    &quot;xticks&quot;: (),
    &quot;yticks&quot;: (),
    &quot;aspect&quot;: &quot;equal&quot;
})
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[272]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[[], [], None]
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorial_algorithm_explained_44_1.png" src="../_images/tutorial_algorithm_explained_44_1.png" />
</div>
</div>
<p>We expect to find two clusters (an inner and an outer ring) in this data set. We will at first compute the neighbourhoods for all points with respect to a radius of <span class="math notranslate nohighlight">\(r = 0.5\)</span>. Below we show the neighbourhood for the first point in the set.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[370]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>r = 0.7
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[371]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>def point_zoom(data, point, ax):
    ax.plot(*data.T, &quot;k.&quot;)
    ax.plot(*data[point].T, &quot;r.&quot;)

    neighbourhood = mpl.patches.Circle(
        data[point], r,
        edgecolor=&quot;k&quot;,
        facecolor=&quot;grey&quot;
    )
    ax.add_patch(neighbourhood)

    limit_factor = 1.2
    ax.set_xlim(data[point][0] - r * limit_factor,
                data[point][0] + r * limit_factor)
    ax.set_ylim(data[point][1] - r * limit_factor,
                data[point][1] + r * limit_factor)
    ax.set(**{
        &quot;xticks&quot;: (),
        &quot;yticks&quot;: (),
        &quot;aspect&quot;: &quot;equal&quot;
    })
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[372]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>fig, ax = plt.subplots()
point_zoom(noisy_circles, 0, ax=ax)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorial_algorithm_explained_48_0.png" src="../_images/tutorial_algorithm_explained_48_0.png" />
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[373]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>tree = cKDTree(noisy_circles)
neighbourhoods = [set(x) for x in tree.query_ball_point(noisy_circles, r)]
for i, s in enumerate(neighbourhoods):
    # Avoid neighbour self-counting
    s.remove(i)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[381]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>def check_similarity(a, b, c):
    if len(a &amp; b) &gt;= c:
        return 1
    return False

def cnn_from_neighbourhoods(
        neighbourhoods, c, yield_iterations=False):
    &quot;&quot;&quot;&quot;&quot;&quot;

    n = len(neighbourhoods)
    visited = [False for _ in range(n)]
    labels = [0 for _ in range(n)]
    queue = deque()
    current = 1

    for point in range(n):
        # Source node
        if visited[point]:
            continue

        visited[point] = True

        neighbours = neighbourhoods[point]
        if len(neighbours) &lt;= c:
            continue

        labels[point] = current

        if yield_iterations:
            yield (point,
                   None,
                   current,
                   labels,
                   visited)
        while True:
            for member in neighbours:
                if visited[member]:
                    continue

                neighbour_neighbours = neighbourhoods[member]
                if len(neighbour_neighbours) &lt;= c:
                    continue

                if check_similarity(neighbours, neighbour_neighbours, c):
                    labels[member] = current
                    visited[member] = True
                    queue.append(member)

                        if yield_iterations:
            yield (point,
                   None,
                   current,
                   labels,
                   visited)

            if not queue:
                break

            point = queue.popleft()
            neighbours = neighbourhoods[point]

        current += 1
    return labels
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[382]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>labels = cnn_from_neighbourhoods(neighbourhoods, 5)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[384]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>gen = cnn_from_neighbourhoods(neighbourhoods, 5, yield_iterations=True)
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[379]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>fig, ax = plt.subplots()
ax.scatter(*noisy_circles.T, c=labels)
ax.set(**{
    &quot;xticks&quot;: (),
    &quot;yticks&quot;: (),
    &quot;aspect&quot;: &quot;equal&quot;
})
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[379]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[[], [], None]
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorial_algorithm_explained_53_1.png" src="../_images/tutorial_algorithm_explained_53_1.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[378]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>plt_iteration(173, save=True, o=&quot;initial&quot;)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
<span class="ansi-red-intense-fg ansi-bold">---------------------------------------------------------------------------</span>
<span class="ansi-red-intense-fg ansi-bold">NameError</span>                                 Traceback (most recent call last)
<span class="ansi-green-intense-fg ansi-bold">&lt;ipython-input-378-6f0a6a5ae5b4&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span>
<span class="ansi-green-intense-fg ansi-bold">----&gt; 1</span><span class="ansi-yellow-intense-fg ansi-bold"> </span>plt_iteration<span class="ansi-yellow-intense-fg ansi-bold">(</span><span class="ansi-cyan-intense-fg ansi-bold">173</span><span class="ansi-yellow-intense-fg ansi-bold">,</span> save<span class="ansi-yellow-intense-fg ansi-bold">=</span><span class="ansi-green-intense-fg ansi-bold">True</span><span class="ansi-yellow-intense-fg ansi-bold">,</span> o<span class="ansi-yellow-intense-fg ansi-bold">=</span><span class="ansi-blue-intense-fg ansi-bold">&#34;initial&#34;</span><span class="ansi-yellow-intense-fg ansi-bold">)</span>

<span class="ansi-red-intense-fg ansi-bold">NameError</span>: name &#39;plt_iteration&#39; is not defined
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[29]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>plt_iteration(173, cdict={1: [173]}, save=True, o=&quot;initial_assigned&quot;)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorial_algorithm_explained_55_0.png" src="../_images/tutorial_algorithm_explained_55_0.png" />
</div>
</div>
</div>
</div>
<div class="section" id="2">
<h1>2<a class="headerlink" href="#2" title="Permalink to this headline">¶</a></h1>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[30]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>plt_iteration(173, 8, cdict={1: [173]}, save=True, o=&quot;candidate&quot;)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorial_algorithm_explained_57_0.png" src="../_images/tutorial_algorithm_explained_57_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[31]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>plt_iteration(
    173, 8,
    cnn=[98, 100, 69, 168, 27, 113, 115, 85, 26, 187, 60, 63,],
    cdict={1: [173]},
    save=True,
    o=&quot;candidate_neighbours&quot;
)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorial_algorithm_explained_58_0.png" src="../_images/tutorial_algorithm_explained_58_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[32]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>plt_iteration(
    173, 8,
    cnn=[98, 100, 69, 168, 27, 113, 115, 85, 26, 187, 60, 63,],
    cdict={1: [173, 8]},
    save=True, o=&quot;candidate_assigned&quot;
)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorial_algorithm_explained_59_0.png" src="../_images/tutorial_algorithm_explained_59_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[33]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>plt_iteration(
    173, 187,
    cdict={1: [8, 10, 26, 27, 30, 32, 50, 60, 63, 69, 85, 98, 100, 113, 115, 128, 135, 163, 164, 168, 173, 187]},
    save=True, o=&quot;further_assigned&quot;
)


</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorial_algorithm_explained_60_0.png" src="../_images/tutorial_algorithm_explained_60_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[34]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>plt_iteration(
    10, 3,
    cdict={1: [8, 10, 26, 27, 30, 32, 50, 60, 63, 69, 85, 98, 100, 113, 115, 128, 135, 163, 164, 168, 173, 187]},
    save=True, o=&quot;grow_candidate&quot;
)

</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorial_algorithm_explained_61_0.png" src="../_images/tutorial_algorithm_explained_61_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[35]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>plt_iteration(
    10, 108,
    cdict={1: [3, 8, 10, 26, 27, 30, 32, 50, 60, 63, 69, 85, 98, 100, 113, 115, 128, 135, 163, 164, 168, 173, 187]},
    save=True, o=&quot;grow_candidate_assigned&quot;
)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorial_algorithm_explained_62_0.png" src="../_images/tutorial_algorithm_explained_62_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[36]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>plt_iteration(
    27, 2,
    cdict={1: [3, 8, 10, 26, 27, 30, 32, 50, 60, 63, 69, 85, 98, 100, 113, 115, 128, 135, 163, 164, 168, 173, 187]},
    save=True, o=&quot;grow_further&quot;
)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorial_algorithm_explained_63_0.png" src="../_images/tutorial_algorithm_explained_63_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[37]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>plt_iteration(
    195, 180,
    cdict={1: [2, 3, 6, 7, 8, 9, 10, 11, 12, 13, 14, 17, 19, 21, 23, 24, 25, 26, 27, 28, 30, 32, 34, 39, 42, 43, 44, 46, 47, 50, 56, 57, 59, 60, 61, 63, 64, 66, 69, 70, 71, 72, 79, 82, 85, 88, 91, 95, 96, 98, 100, 103, 107, 108, 110, 113, 115, 116, 117, 118, 119, 121, 122, 124, 126, 127, 128, 130, 134, 135, 137, 140, 142, 143, 144, 145, 148, 150, 160, 162, 163, 164, 166, 167, 168, 173, 174, 180, 182, 184, 185, 186, 187, 190, 192, 193, 195, 196, 197, 199]},
    limitf=4,
    save=True, o=&quot;cluster1_done&quot;
)

</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorial_algorithm_explained_64_0.png" src="../_images/tutorial_algorithm_explained_64_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[38]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>plt_iteration(
    4, 0,
    cdict={
        1: [2, 3, 6, 7, 8, 9, 10, 11, 12, 13, 14, 17, 19, 21, 23, 24, 25, 26, 27, 28, 30, 32, 34, 39, 42, 43, 44, 46, 47, 50, 56, 57, 59, 60, 61, 63, 64, 66, 69, 70, 71, 72, 79, 82, 85, 88, 91, 95, 96, 98, 100, 103, 107, 108, 110, 113, 115, 116, 117, 118, 119, 121, 122, 124, 126, 127, 128, 130, 134, 135, 137, 140, 142, 143, 144, 145, 148, 150, 160, 162, 163, 164, 166, 167, 168, 173, 174, 180, 182, 184, 185, 186, 187, 190, 192, 193, 195, 196, 197, 199],
        2: [4]
    },
    limitf=2,
    save=True, o=&quot;init_cluster2&quot;
)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorial_algorithm_explained_65_0.png" src="../_images/tutorial_algorithm_explained_65_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[39]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>plt_iteration(
    29, 20,
    cdict={
        1: [2, 3, 6, 7, 8, 9, 10, 11, 12, 13, 14, 17, 19, 21, 23, 24, 25, 26, 27, 28, 30, 32, 34, 39, 42, 43, 44, 46, 47, 50, 56, 57, 59, 60, 61, 63, 64, 66, 69, 70, 71, 72, 79, 82, 85, 88, 91, 95, 96, 98, 100, 103, 107, 108, 110, 113, 115, 116, 117, 118, 119, 121, 122, 124, 126, 127, 128, 130, 134, 135, 137, 140, 142, 143, 144, 145, 148, 150, 160, 162, 163, 164, 166, 167, 168, 173, 174, 180, 182, 184, 185, 186, 187, 190, 192, 193, 195, 196, 197, 199],
        2: [0, 1, 4, 29, 35, 37, 49, 54, 68, 75, 78, 83, 84, 94, 101, 120, 132, 136, 138, 149, 151, 157, 165, 169, 170, 171, 177, 181, 188, 191,]
    },
    limitf=4,
    save=True, o=&quot;grow_cluster2&quot;
)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorial_algorithm_explained_66_0.png" src="../_images/tutorial_algorithm_explained_66_0.png" />
</div>
</div>
</div>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../index.html">cnnclustering</a></h1>



<p class="blurb">CNN clustering and csMSM estimation in Python</p>




<p>
<iframe src="https://ghbtns.com/github-btn.html?user=janjoswig&repo=CNN&type=watch&count=true&size=large&v=2"
  allowtransparency="true" frameborder="0" scrolling="0" width="200px" height="35px"></iframe>
</p>





<h3>Navigation</h3>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../_source/install.html">Installation instructions</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../_source/tutorials.html">Tutorials</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="basic_usage.html">Basic usage of the cnn module</a></li>
<li class="toctree-l2"><a class="reference internal" href="scikit_learn_datasets.html">scikit-learn Toy data sets</a></li>
<li class="toctree-l2"><a class="reference internal" href="hierarchical_clustering_basics.html">Hierarchical clustering basics</a></li>
<li class="toctree-l2"><a class="reference internal" href="data_input_formats.html">Data input formats</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Density based clustering explained</a></li>
<li class="toctree-l2"><a class="reference internal" href="#2">2</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../_source/api_reference.html">API Reference</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
  <li><a href="../_source/tutorials.html">Tutorials</a><ul>
      <li>Previous: <a href="data_input_formats.html" title="previous chapter">Data input formats</a></li>
      <li>Next: <a href="../_source/api_reference.html" title="next chapter">API Reference</a></li>
  </ul></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2020, Jan-Oliver Joswig.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 3.1.1</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="../_sources/tutorial/algorithm_explained.ipynb.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>