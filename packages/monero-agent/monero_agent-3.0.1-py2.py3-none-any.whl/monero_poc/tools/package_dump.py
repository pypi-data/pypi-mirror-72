"""
Measures package memory sizes.

## Usage
python monero_poc/tools/package_dump.py \
    --config trezor-pkg-config.json \
    --size /tmp/psizes.json \
    --root-dir ~/workspace/trezor-firmware

If package deps rendering is not desired (takes some time),
add options --no-graphviz --no-render

## Requirements
pip install -U networkx matplotlib graphviz coloredlogs trezor monero-agent
"""

import ast
import argparse
import asyncio
import binascii
import io
import logging
import os
import random
import re
import sys
import json
import time
import re
import itertools
import threading
import coloredlogs

import networkx as nx

import matplotlib
matplotlib.use('PS')  # https://github.com/scikit-optimize/scikit-optimize/issues/637
import matplotlib.pyplot as plt

from monero_glue.messages import DebugMoneroDiagRequest


logger = logging.getLogger(__name__)
coloredlogs.CHROOT_FILES = []
coloredlogs.install(level=logging.DEBUG, use_chroot=False)


# System-provided packages
PACKAGES = [
    "array",
    "cmath",
    "collections",
    "gc",
    "json",
    "logging",
    "machine",
    "math",
    "re",
    "struct",
    "sys",
    "time",
    "typing",
    "ubinascii",
    "ucollections",
    "uerrno",
    "uhashlib",
    "uheapq",
    "ujson",
    "ure",
    "ustruct",
    "utime",
]


def defvalkey(js, key, default=None, take_none=True):
    if js is None:
        return default
    if key not in js:
        return default
    if js[key] is None and not take_none:
        return default
    return js[key]


def remove_py(py):
    return re.sub(r'\.py$', '', py)


def to_pkg(tp):
    if not tp:
        return ''
    return '.'.join(tp)


def to_tup(pkg):
    return tuple(pkg.split('.'))


def mylay(shells):
    """Custom graph layout"""
    res = {}
    for lvl, sh in enumerate(shells):
        ch = 1000 / (len(sh)+1)
        for i, p in enumerate(sh):
            res[p] = ch+i*ch, -100*lvl
    return res


class PathCfg:
    def __init__(self, path, depth=-1, alias=None, exclude=None):
        self.path = os.path.abspath(path)
        self.is_dir = os.path.isdir(self.path)
        self.depth = depth
        self.alias = [] if alias is None else (alias.split('.') if isinstance(alias, str) else alias)
        self.exclude = set(exclude) if exclude else set()

    @classmethod
    def from_json(cls, js):
        return cls(js['path'],
                   defvalkey(js, 'depth'),
                   defvalkey(js, 'alias'),
                   defvalkey(js, 'exclude'),
                )

    def __repr__(self):
        return 'PathCfg(%r, %r, %r)' % (self.path, self.depth, self.alias)


class ProcFile:
    def __init__(self, path=None, data=None, src=None, pkg=None, import_st=None, is_main_pkg=False):
        self.path = path
        self.data = data
        self.src = src
        self.pkg = tuple() if not pkg else pkg
        self.import_st = tuple() if not import_st else import_st
        self.is_main_pkg = is_main_pkg

    def full_import(self, level=0):
        if level == 0:
            return self.import_st

        if self.is_main_pkg:
            level -= 0

        return self.import_st[:-level]

    def __repr__(self):
        return 'File(%r, %r B, %r, %r, %r)' % (self.path, len(self.data), self.pkg, self.import_st, self.src)


class ImportStatement:
    def __init__(self, module, name, alias=None, level=0, node=None, src=None):
        self.module = module
        self.name = name
        self.alias = alias
        self.level = level
        self.node = node
        self.src = src  # type: ProcFile
        self.root_pkg = None  # generated by user

    def full_import(self):
        im = []
        if self.module:
            im += self.module.split('.')
        im += self.name.split('.')

        if self.src is None:
            return im

        if self.level > 0:
            im = list(self.src.full_import(self.level)) + im

        return im

    @classmethod
    def from_package(cls, root_pkg, src=None):
        root_pkg = root_pkg.split('.') if isinstance(root_pkg, str) else list(root_pkg)
        r = cls(to_pkg(root_pkg[:-1]), root_pkg[-1])
        r.root_pkg = tuple(root_pkg)
        r.src = src
        return r

    def __repr__(self):
        return 'Import(%r, %r, %r, %r, full=%r, nd=%r)' % (
            self.module,
            self.name,
            self.alias,
            self.level,
            self.full_import() if self.module and self.name else 0,
            self.root_pkg,
            # ast.dump(self.node) if self.node else 0,
        )


class PyImportVisitor(ast.NodeVisitor):
    """Import visitor object for AST"""
    def __init__(self, src, max_depth=3):
        self.imports = []
        self.src = src
        self.max_depth = max_depth

    def visit(self, node, depth=0):
        """Visit a node."""
        method = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method, self.generic_visit)
        return visitor(node, depth)

    def base_generic_visit(self, node, depth=0):
        """Called if no explicit visitor function exists for a node."""
        for field, value in ast.iter_fields(node):
            if isinstance(value, list):
                for item in value:
                    if isinstance(item, ast.AST):
                        self.visit(item, depth + 1)
            elif isinstance(value, ast.AST):
                self.visit(value, depth + 1)

    def visit_Import(self, node, depth=0):
        if depth > 1:
            return

        for cn in node.names:
            self.on_global_import(None, cn.name, cn.asname, 0, node)

        self.generic_visit(node)

    def visit_ImportFrom(self, node, depth=0):
        if depth > 1:
            return

        for cn in node.names:
            self.on_global_import(node.module, cn.name, cn.asname, node.level, node)

        self.generic_visit(node)

    def generic_visit(self, node, depth=0):
        # print((' ' * depth) + node.__class__.__name__, ast.dump(node))
        if depth > self.max_depth:
            return
        self.base_generic_visit(node, depth)

    def on_global_import(self, module, name, alias=None, level=0, node=None):
        self.imports.append(ImportStatement(module, name, alias, level, node, self.src))
        # print(module, name, alias, level, node.__class__.__name__, ast.dump(node))


class TrezorDiag:
    """Simple Trezor connector / client"""
    def __init__(self):
        self.trezor_proxy = None  # type: TokenProxy
        self.loop = asyncio.get_event_loop()
        self.worker_loop = asyncio.new_event_loop()
        self.worker_thread = threading.Thread(
            target=self.looper, args=(self.worker_loop,)
        )
        self.worker_thread.setDaemon(True)
        self.worker_thread.start()

    def looper(self, loop):
        asyncio.set_event_loop(loop)
        loop.run_forever()

    def submit_coro(self, coro):
        return asyncio.run_coroutine_threadsafe(coro, self.worker_loop)

    def wait_coro(self, coro):
        future = self.submit_coro(coro)
        return future.result()

    def connect(self):
        tpath = os.getenv('TREZOR_PATH', 'udp:127.0.0.1:21324')

        # if self.args.patch_client:
        #     self.monkey_patch_trezorlib()

        from monero_glue.trezor import manager as tmanager
        self.trezor_proxy = tmanager.Trezor(path=tpath, debug=True)

    def diag(self, msg):
        try:
            resp = self.wait_coro(self.trezor_proxy.call(msg))
            return resp

        except Exception as e:
            logger.warning(e)

    def get_mods(self):
        msg = DebugMoneroDiagRequest(ins=10, p1=0, p2=0)
        resp = self.wait_coro(self.trezor_proxy.call(msg))
        return json.loads(resp.data1)

    def import_mod(self, m1, m2):
        msg = DebugMoneroDiagRequest(ins=11, p1=0, p2=0,
                                     data1=json.dumps([m1, m2]).encode('utf8'))

        resp = self.wait_coro(self.trezor_proxy.call(msg))
        return json.loads(resp.data1)


class PackageDump:
    def __init__(self):
        self.paths = []
        self.packages = {}  # type: dict[tuple, ProcFile]
        self.imports = {}  # type: dict[tuple, list[ImportStatement]]
        self.sizes = {}  # type: dict[tuple, int]
        self.self_size = {}  # type: dict[tuple, int]
        self.G = None
        self.G2 = None
        self.shells = []
        self.layers = []
        self.topo_order = []
        self.conn = TrezorDiag()

    async def work(self):
        self.import_packages(PACKAGES)
        self.read_config()

        proc_files = list(self.read_paths())
        proc_files.sort(key=lambda x: x.path)

        self.packages = {**self.packages, **{k.import_st: k for k in proc_files}}
        logger.info('All found packages: %s' % (sorted(self.packages.keys())))

        self.process_deps(proc_files)
        self.compute_graphs()
        self.plot_deps()

        print('-'*100)
        print('-'*100)
        print('-'*100)

        # Connect to trezor and determine package sizes
        self.conn.connect()

        # mods = self.conn.get_mods()
        # print(mods)

        if self.args.sizes and os.path.exists(self.args.sizes) and not self.args.recompute_sizes:
            logger.info('Loading package sizes from cache (no measurement)')
            self.load_package_sizes(json.load(open(self.args.sizes)))

        else:
            self.compute_pkg_sizes()
            csizes = [(to_pkg(k), self.sizes[k]) for k in self.sizes]
            json.dump(sorted(csizes), open(self.args.sizes or '/tmp/sizes.json', 'w+'), indent=2)

        print(json.dumps([(to_pkg(k), self.sizes[k]) for k in self.sizes], indent=2))

        # msg = DebugMoneroDiagRequest(ins=10, p1=0, p2=0)
        # r = self.conn.diag(msg)
        # logger.info("DONE")
        # print(r)

        # Self-sizes computation (size of the package minus dependencies)
        self.self_size_computation()

    def self_size_computation(self):
        for cp in self.topo_order:
            cpt = to_tup(cp)
            if cpt not in self.sizes:
                # If the import imports a method/object from the module the size of the import
                # cannot be computed, the module is imported as a whole.
                logger.info('Could not resolve size: %s (maybe object import?)' % to_pkg(cpt))
                continue

            dep_size = 0
            deps = self.imports[cpt] if cpt in self.imports else []
            for dep in deps:
                depp = dep.root_pkg
                if depp not in self.sizes:
                    logger.info('  Could not get dep size: %s' % (depp,))
                    continue

                dep_size += self.sizes[depp]

            self.self_size[cpt] = self.sizes[cpt] - dep_size

        rsizes = [(to_pkg(k), self.self_size[k]) for k in self.self_size]
        json.dump(sorted(rsizes), open('/tmp/rsizes.json', 'w+'), indent=2)

    def fix_path(self, pth):
        if os.path.isabs(pth):  # absolute
            return pth
        return os.path.join(self.args.root_dir, pth)

    def read_config(self):
        for fl in self.args.files:
            self.paths.append(PathCfg(self.fix_path(fl)))

        if self.args.config:
            js = json.load(open(self.args.config))
            for r in js['paths']:
                r['path'] = self.fix_path(r['path'])
                self.paths.append(PathCfg.from_json(r))

            if 'packages' in js:
                self.import_packages([x['full'] for x in js['packages']])

        self.sizes[('typing',)] = 0  # manual set as typing is not used in production micropython
        logger.info('Loaded paths: %s' % self.paths)

    def read_paths(self):
        for c in self.paths:  # type: PathCfg
            logger.info('Processing: %s' % c)

            as_dir = False
            data = None
            if c.path == '-':
                data = sys.stdin.read()
            elif not c.is_dir:
                data = open(c.path).read()
            else:
                as_dir = True

            if not as_dir:
                yield ProcFile(c.path, data, c, tuple(), tuple([remove_py(c.path)]) if c.path != '-' else tuple([]))
                continue

            absroot = os.path.abspath(c.path)
            for root, dirs, files in os.walk(absroot):
                subdir = root[len(absroot) + 1:]
                pkg = subdir.split('/') if subdir else []
                cdepth = (subdir.count('/') + 1) if subdir else 0
                if c.alias:
                    pkg = c.alias + pkg

                if c.depth is not None and cdepth >= c.depth:
                    continue

                if subdir in c.exclude:
                    logger.debug('Excluded: %s' % subdir)
                    continue

                logger.debug('%s | sub=%s | d=%s | pkg=%s' % (c.path, subdir, cdepth, pkg))
                for fl in files:
                    full_path = os.path.join(root, fl)
                    is_main_pkg = fl == '__init__.py'
                    if os.path.isdir(full_path):
                        continue
                    if not fl.endswith('.py'):
                        continue

                    data = open(full_path).read()
                    import_st = tuple(pkg if is_main_pkg else (pkg + [remove_py(fl)]))
                    yield ProcFile(full_path, data, c, pkg, import_st, is_main_pkg)

    def find_package(self, import_path):
        ln = len(import_path)
        while ln > 0:
            cp = tuple(import_path[:ln])
            if cp in self.packages:
                return cp

            ln -= 1
        logger.debug('Could not find package for: %s' % import_path)
        return import_path

    def import_packages(self, pkgs):
        for pkg in pkgs:
            cpkg = tuple(pkg.split('.'))
            self.packages[cpkg] = ProcFile(import_st=cpkg)
            logger.info('Added package: %s' % (cpkg,))

    def new_import(self, root_pkg):
        src = defvalkey(self.packages, root_pkg)
        return ImportStatement.from_package(root_pkg, src=src)

    def process_deps(self, proc_files):
        logger.info('Processing deps...')
        for pf in proc_files:  # type: ProcFile
            try:
                pf_imp = tuple(pf.full_import())
                pf_str = '.'.join(pf_imp)
                logger.debug('Processing: %s' % pf_str)

                self.imports[pf_imp] = []

                py_visitor = PyImportVisitor(pf)
                md = ast.parse(pf.data)
                py_visitor.visit(md)
                imports = py_visitor.imports

                for imp in imports:  # type: ImportStatement
                    ifull = imp.full_import()
                    pk = self.find_package(ifull)
                    imp.root_pkg = pk
                    self.imports[pf_imp].append(imp)
                    # logger.debug('  .. %s' % imp)

            except Exception as e:
                logger.warning('Parsing error: %s, fl: %s' % (e, pf.path))

    def compute_pkg_sizes(self):
        logger.info('Computing package sizes...')
        for p in self.packages:
            p = list(p)
            if not p:
                continue

            logger.debug('Importing %s' % (to_pkg(p)))
            m1, m2 = to_pkg(p[:-1]), p[-1]
            try:
                r = self.conn.import_mod(m1, m2)
                self.sizes[tuple(p)] = max(0, r)
                logger.debug(' .. %s = size: %s' % (to_pkg(p), r))

            except Exception as e:
                logger.debug('Could not import %s' % to_pkg(p))

    def load_package_sizes(self, js):
        for r in js:
            pkg = tuple(r[0].split('.'))
            self.sizes[pkg] = max(0, r[1])

    def compute_graphs(self):
        self.G = nx.DiGraph()

        if not self.args.no_graphviz:
            from graphviz import Digraph
            self.G2 = Digraph(comment='Deps graph')

        edges = set()
        seen = set()
        queue = []

        for pkg in self.packages:
            if pkg and to_pkg(pkg).startswith('apps.monero'):
                queue.append((None, self.new_import(pkg), 0))

        # src = ('apps', 'monero', 'xmr', 'key_image')
        # iis = self.new_import(src)

        while len(queue) > 0:
            src, cur, depth = queue[0]
            queue = queue[1:]
            print(cur)

            logger.debug('  %s | %s' % (cur.root_pkg, len(queue)))

            self.G.add_node(to_pkg(cur.root_pkg))
            if self.G2:
                self.G2.node(to_pkg(cur.root_pkg), to_pkg(cur.root_pkg))
            self.layers.append((cur.root_pkg, depth))

            if src:
                if self.G2:
                    self.G2.node(to_pkg(src), to_pkg(src))
                self.G.add_node(to_pkg(src))

                ce = to_pkg(src), to_pkg(cur.root_pkg)
                rev = to_pkg(cur.root_pkg), to_pkg(src)  # cycle prot, simple
                if ce not in edges and rev not in edges:
                    self.G.add_edge(to_pkg(src), to_pkg(cur.root_pkg))
                    if self.G2:
                        self.G2.edge(to_pkg(src), to_pkg(cur.root_pkg))
                    edges.add(ce)

            if cur.root_pkg in seen:
                continue

            seen.add(cur.root_pkg)
            if cur.root_pkg in self.imports:
                queue += [(cur.root_pkg, x, depth + 1) for x in self.imports[cur.root_pkg]]

        self.shells = []
        for k, g in itertools.groupby(sorted(self.layers, key=lambda x: x[1]), lambda x: x[1]):
            self.shells.append([to_pkg(x[0]) for x in g])

        # Cycle breakdown
        # In order to compute package memory footprint we need to compute
        # dependencies. Package sizes are resolved in the topological order.
        # For that we need DAG, acyclic.
        #
        # Alternative is to contract found cycles to a single node and treat it as a whole.
        while True:
            cycle = None
            try:
                cycle = list(nx.find_cycle(self.G))
            except:
                pass

            if not cycle:
                break

            logger.warning('Cycle found: %s' % cycle)
            edge_removed = False
            for edge in cycle:
                if edge[0].startswith('trezor') and edge[1].startswith('apps'):
                    self.G.remove_edge(edge[0], edge[1])
                    edge_removed = True

            if not edge_removed:
                raise ValueError('Could not remove the cycle')

        # Topo sort
        self.topo_order = list(reversed(list(nx.topological_sort(self.G))))
        print('Topological ordering: ', self.topo_order)

        # ng = self.G.copy()
        # for i in range(20):
        #     print('-'*100)
        #     print('I: %s' % i)
        #
        #     roots = list(v for v, d in ng.in_degree() if d == 0)
        #     leaves = list(v for v, d in ng.out_degree() if d == 0)
        #     print('Roots  ', roots)
        #     print('Leaves ', leaves)
        #     if len(leaves) == 0:
        #         print(list(nx.simple_cycles(ng)))
        #
        #     ng.remove_nodes_from(leaves)

    def plot_deps(self):
        if self.args.no_render:
            return
        logger.info('Rendering deps...')
        # print('-' * 100)
        # print(self.imports[('apps', 'monero', 'xmr', 'bulletproof')])
        # for x in self.imports[('trezor', 'ui', 'passphrase')]:
        #     print(x)
        # print('-' * 100)
        # for x in self.imports[('trezor', 'ui')]:
        #     print(x)
        # print('-' * 100)

        plt.figure(figsize=(24, 24))
        # nx.draw_networkx(G, with_labels=True)
        # nx.draw(G, with_labels=True)
        # nx.draw(G, with_labels=True, pos=nx.circular_layout(G))
        # nx.draw(G, with_labels=True, pos=nx.kamada_kawai_layout(G))
        # nx.draw(G, with_labels=True, pos=nx.shell_layout(G, shells))
        nx.draw(self.G, with_labels=True, pos=mylay(self.shells))
        plt.savefig("/tmp/deps.png", dpi=400)
        # plt.show()

        if not self.G2:
            return

        try:
            logger.info('Graphviz rendering...')
            # G2.engine = 'neato'
            self.G2.render('/tmp/package-deps.pdf', view=False)
        except Exception as e:
            logger.exception('Could not render Graphviz', exc_info=e)

    async def main(self):
        parser = argparse.ArgumentParser(
            description="Python packages dump"
        )

        parser.add_argument(
            "--root-dir",
            dest="root_dir",
            required=True,
            default=None,
            help="Root dir for trezor-firmware"
        )

        parser.add_argument(
            "--config",
            dest="config",
            default=None,
            help="JSON config file"
        )

        parser.add_argument(
            "--sizes",
            dest="sizes",
            default=None,
            help="JSON package sizes file (output/cache)"
        )

        parser.add_argument(
            "--no-render",
            dest="no_render",
            default=False,
            action="store_const",
            const=True,
            help="Disables graph rendering (faster run)"
        )

        parser.add_argument(
            "--no-graphviz",
            dest="no_graphviz",
            default=False,
            action="store_const",
            const=True,
            help="Disables graphviz support"
        )

        parser.add_argument(
            "--recompute-sizes",
            dest="recompute_sizes",
            default=False,
            action='store_const',
            const=True,
            help="Forces package sizes recomputation even if size JSON cache is provided (Trezor measurement)"
        )

        parser.add_argument(
            "files",
            nargs="*",
            help="files to read, if empty, stdin is used",
        )

        self.args = parser.parse_args()
        return await self.work()


async def amain():
    tgen = PackageDump()
    res = await tgen.main()
    sys.exit(res)


def main():
    loop = asyncio.get_event_loop()
    loop.run_until_complete(amain())
    loop.close()


if __name__ == "__main__":
    main()
