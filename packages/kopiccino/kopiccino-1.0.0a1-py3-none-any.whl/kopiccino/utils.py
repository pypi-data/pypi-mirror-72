# coding: utf8
"""Helper functions, utilites, etc."""

import ast
import io
import logging
import os
import shutil
import sys
import pathlib
import re
from typing import Tuple
import zipfile

import coloredlogs

import requests
from tqdm import tqdm

from .__about__ import __version__
from .exceptions import KopiError

PACKAGE_ATTRIBUTES = {
    "name": None,
    "author": None,
    "license": None,
    "copyright": "",
    "version": None,
    "doc": "",
    "maintainer": "",
    "email": "",
    "pip_requires": [],
}

# String parsing from https://stackoverflow.com/a/19675957
RE_META_ATTR = re.compile(r"\_\_([a-z]+)\_\_ *= *['\"](.*?)['\"]")
EMPTY_ZIP_FILE = b"PK\x05\x06\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00"
TOML_CONF_HEADER = f"# Generated by kopiccino v{__version__}\n"

REQ_TIMEOUT = 5
REQ_ITER_CHUNK = 1024
LOG_FORMAT='%(asctime)s %(message)s'

os.environ["COLOUREDLOGS_LOG_FORMAT"] = LOG_FORMAT


def get_logger(name: str, level: str = "DEBUG", suppress: bool = True) -> logging.Logger:
    """Create a new logger.
    
    Args:
        name: The name to assign to the logger.
        level (default: DEBUG): Must be a standard logging level.
        suppress (default: True): Whether or not to ignore log messages from othee loggers.
    
    Returns:
        The logger.
    """
    
    logger = logging.getLogger(name)
    coloredlogs.install(level=level, logger=logger)
    return logger


def _fill_defaults(data: dict, defaults: dict):
    """Fill in default values into a dictionary.
    
    Args:
        data: The dictionary to fill with default values.
        defaults: The default values. If a key in defaults is not found in data, the
        value of the key in defaults will be put into data.
        If the value of the key in defaults is None, a KeyError will be raised.
    """

    for key, value in defaults.items():
        result = data.get(key, None)
        if result is None:
            if value is not None:
                data[key] = value
            else:
                raise KeyError(f"field required: {key}")


def copypath(src: str, dst: str) -> None:
    """Copy a path to a destination.
    
    Args:
        src: The path to copy. Must be an existing file/directory.
        dst: The path to copy to. Must be an directory.
    
    Returns:
        None.
    """

    src = pathlib.Path(src)

    if src.is_file():
        shutil.copy2(src, dir)

    elif src.is_dir():
        folder_dest = pathlib.Path(dst) / src.name
        shutil.copytree(src, folder_dest)

    else:
        raise shutil.Error("src is not a file or dir")


def valid_module_path(pth: pathlib.Path) -> str:
    """Check if a path to a Python module is valid (either ends with ".py",
    or is a folder with a __init__.py file).
    
    Returns:
        "file" or "dir" if the path exists and is a Python module, "" if the
            path does not exist/is not a valid Python module.
    """

    pth = pathlib.Path(pth)

    return (pth.is_file() and pth.suffix == ".py") or (
        pth.is_dir() and (pth / "__init__.py").is_file()
    )


def autogen_metadata(module_path: str) -> dict:
    """Generate metadata for a kopiccino package from a Python module (.py file).

    Basically, we find all __{ATTR}__ constants that are defined and return them.
    
    Args:
        module_path: The path to the module, must be a standalone Python script.

    Raises:
        SyntaxError, if the module code is invalid.
    
    Returns:
        dict: The metadata generated.
    """

    metadata = {}
    module_path = pathlib.Path(module_path).resolve().expanduser()
    metadata["name"] = module_path.stem

    try:
        with module_path.open("r", encoding="utf-8") as f:
            data = f.read()

    except FileNotFoundError:
        data = ""

    metadata["docstring"] = ast.get_docstring(ast.parse(data))

    attrs = [line for line in data.splitlines() if line.startswith("__")]

    for line in attrs:
        try:
            attr, attr_data = RE_META_ATTR.findall(line)[0]

        except (TypeError, ValueError):
            continue

        else:
            metadata[attr] = attr_data

    return metadata


def zipdir(path: pathlib.Path, zf: zipfile.ZipFile) -> zipfile.ZipFile:
    """Compress a directory's contents into a ZipFile.
    
    Args:
        path: The path to the directory.
        zf: The zipfile object to write to.
    
    Returns:
        The zipfile object that was written to.
    
    Raises:
        NotADirectoryError, if the path is not a directory.
        TypeError, if the zipfile is not a ZipFile object.
    """

    pth = pathlib.Path(path)
    if not path.is_dir():
        raise NotADirectoryError("can't compress path: not a directory")

    if not isinstance(zf, zipfile.ZipFile):
        raise TypeError("not a zipfile")

    for root, dirs, files in os.walk(pth):
        for file in files:
            filepath = pathlib.Path(root) / file
            relpath = pth.name / filepath.relative_to(pth)
            # print(relpath)
            zf.write(filepath, arcname=relpath)

    return zf


def download_url(
    url: str, pbar: bool = False, timeout: int = REQ_TIMEOUT
) -> Tuple[bytes, requests.models.Response]:
    """ï¿¼Download a URL.
    
    Args:
        url: The URL to download.
        pbar: Whether or not to present a progress bar during the download.
    
    Returns:
        A two-tuple of the bytes downloaded and the response object from requests.get.
    """
    response = requests.get(url, stream=True, timeout=timeout)
    response.raise_for_status()

    size = int(response.headers.get("Content-Length", 0))

    if pbar:
        buffer = io.BytesIO(b"")
        with tqdm(total=size, unit="iB", unit_scale=True) as pbar:
            for chunk in response.iter_content(REQ_ITER_CHUNK):
                pbar.update(len(chunk))
                buffer.write(chunk)

        return buffer.getbuffer(), response

    else:
        return response.content, response
